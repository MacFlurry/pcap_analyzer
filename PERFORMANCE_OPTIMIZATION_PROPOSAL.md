# Proposition d'Optimisation des Performances - PCAP Analyzer

**Date:** 2025-12-07
**Version:** 3.0.0
**Branche:** performance-optimization

## üìä Probl√®me Identifi√©

### Sympt√¥mes
- **Fichier PCAP:** 116 MB, 634,000 paquets
- **Temps d'analyse:** 6 minutes pour 60,041 flux TCP
- **Vitesse:** ~1,756 paquets/seconde (634k / 360s)

### Contexte
- **17 analyseurs** diff√©rents (timestamps, TCP handshake, RTT, retransmissions, etc.)
- **Scapy** effectue une dissection compl√®te de toutes les couches r√©seau (lent)
- Les analyseurs maintiennent des **dictionnaires et listes** en m√©moire qui grossissent avec le nombre de paquets

---

## üîç Analyse Approfondie des Bottlenecks

### 1. Performance de Scapy

**Scapy est intrins√®quement lent:**
- Performance typique: **600-900 paquets/seconde** ([source](https://stackoverflow.com/questions/38601091/how-to-improve-scapy-performance-reading-large-files))
- Raison: Dissection compl√®te et d√©taill√©e de toutes les couches r√©seau
- Chaque paquet est d√©compos√© en une structure complexe d'objets Python

**Comparaisons de performance:**
- **dpkt:** ~12,431 p/s (10x plus rapide que Scapy) ([source](https://stackoverflow.com/questions/30826123/python-scapy-vs-dpkt))
- **pypacker:** ~17,938 p/s (3x plus rapide que dpkt) ([source](https://github.com/mike01/pypacker))
- **Scapy:** ~726 p/s (r√©f√©rence)

### 2. √âtat Actuel du Code

#### Points Positifs ‚úÖ
- **PcapReader d√©j√† utilis√©** (src/cli.py:44) - streaming au lieu de charger tout en m√©moire
- **Cleanup p√©riodique** dans certains analyseurs (temporal_pattern.py:89, retransmission.py)
- **Limites m√©moire** configur√©es (max_packets_per_source: 1000, max_sources: 500)

#### Bottlenecks Identifi√©s üî¥

**1. Structures de donn√©es volumineuses:**
```python
# retransmission.py (674 lignes) - le plus gros analyseur
self.flow_segments: Dict[str, List[Tuple]] = defaultdict(list)  # Cro√Æt avec chaque paquet TCP
self.flow_stats: Dict[str, FlowStats] = {}  # Un par flux TCP
self.retransmissions: List[TCPRetransmission] = []
self.dup_acks: List[TCPAnomaly] = []
self.out_of_order: List[TCPAnomaly] = []

# rtt_analyzer.py (426 lignes)
self.unacked_segments: Dict[str, List[Tuple]] = defaultdict(list)  # Segments en attente d'ACK
self.rtt_measurements: List[RTTMeasurement] = []
self.flow_stats: Dict[str, FlowRTTStats] = {}

# temporal_pattern.py (432 lignes)
self.time_slots: Dict[int, TimeSlot] = {}  # Un par cr√©neau temporel
self.packet_times_by_source: Dict[str, List[float]] = defaultdict(list)  # Liste de timestamps par IP

# tcp_window.py, dns_analyzer.py, burst_analyzer.py - m√™mes patterns
```

**2. Dissection Scapy compl√®te:**
- Chaque paquet est enti√®rement dissect√© (Ether ‚Üí IP ‚Üí TCP ‚Üí Payload)
- Pas de filtrage des couches non n√©cessaires
- Aucune optimisation conf.layers.filter() utilis√©e

**3. Pas de parall√©lisation:**
- Traitement s√©quentiel paquet par paquet
- Un seul CPU core utilis√© sur les machines multi-core

---

## üí° Solutions Propos√©es

### Option 1: Optimisation Scapy Pure (Recommand√©e pour d√©marrer)

**Impact attendu:** 2-3x plus rapide (2-3 minutes au lieu de 6)

#### Changements:

**1. Filtrage s√©lectif des couches Scapy**
```python
# Dans src/cli.py, avant load_pcap_streaming()
from scapy.config import conf
from scapy.layers.l2 import Ether
from scapy.layers.inet import IP, TCP, UDP, ICMP
from scapy.layers.dns import DNS

# Ne diss√®que que les couches n√©cessaires
conf.layers.filter([Ether, IP, TCP, UDP, ICMP, DNS])
```
[Source: Scapy documentation](https://scapy.readthedocs.io/en/latest/usage.html)

**2. Extraction imm√©diate des donn√©es (pas de stockage d'objets Packet)**
```python
# ‚ùå AVANT: Stocker des objets Scapy (lourd)
self.segments.append((packet, timestamp, seq, ...))

# ‚úÖ APR√àS: Extraire et stocker seulement les donn√©es n√©cessaires
self.segments.append((timestamp, src_ip, dst_ip, src_port, dst_port, seq, ...))
```

**3. Am√©lioration du garbage collection**
```python
# Forcer le GC p√©riodiquement pour les gros fichiers
import gc
if packet_count % 50000 == 0:
    gc.collect()
```

**4. Optimisation des structures de donn√©es**
- Utiliser `__slots__` dans les dataclasses pour r√©duire la m√©moire
- Limiter la taille des listes historiques (FIFO avec deque maxlen)
- Agr√©ger imm√©diatement au lieu de stocker tous les events

**Avantages:**
- ‚úÖ Pas de r√©√©criture majeure
- ‚úÖ Garde toute la puissance de Scapy
- ‚úÖ Changements localis√©s et testables
- ‚úÖ Risque faible

**Inconv√©nients:**
- ‚ö†Ô∏è Gains mod√©r√©s (2-3x)
- ‚ö†Ô∏è Toujours limit√© par la vitesse de Scapy

---

### Option 2: Approche Hybride dpkt + Scapy

**Impact attendu:** 5-10x plus rapide (36-72 secondes au lieu de 6 minutes)

#### Concept:
1. **Phase 1 (dpkt):** Extraction rapide des m√©tadonn√©es de base (10x plus rapide)
2. **Phase 2 (Scapy):** Analyse d√©taill√©e seulement pour les cas complexes

#### Architecture:
```python
# Nouveau module: src/parsers/fast_parser.py
import dpkt

def fast_extract_tcp_metadata(pcap_file):
    """
    Extraction rapide avec dpkt.
    Retourne: liste de m√©tadonn√©es l√©g√®res (pas d'objets Scapy).
    """
    packets_metadata = []

    with open(pcap_file, 'rb') as f:
        pcap = dpkt.pcap.Reader(f)

        for ts, buf in pcap:
            try:
                eth = dpkt.ethernet.Ethernet(buf)
                if not isinstance(eth.data, dpkt.ip.IP):
                    continue

                ip = eth.data
                if not isinstance(ip.data, dpkt.tcp.TCP):
                    continue

                tcp = ip.data

                # Extraire SEULEMENT ce qui est n√©cessaire
                metadata = {
                    'timestamp': ts,
                    'src_ip': socket.inet_ntoa(ip.src),
                    'dst_ip': socket.inet_ntoa(ip.dst),
                    'src_port': tcp.sport,
                    'dst_port': tcp.dport,
                    'seq': tcp.seq,
                    'ack': tcp.ack,
                    'flags': tcp.flags,
                    'window': tcp.win,
                    'payload_len': len(tcp.data)
                }
                packets_metadata.append(metadata)

            except:
                continue  # Skip malformed packets

    return packets_metadata
```

```python
# Modification de src/cli.py
def analyze_pcap_hybrid(pcap_file, config, ...):
    """Analyse hybride dpkt + Scapy."""

    # Phase 1: Extraction rapide avec dpkt (90% des donn√©es)
    console.print("[cyan]Phase 1: Extraction rapide des m√©tadonn√©es (dpkt)...[/cyan]")
    packets_metadata = fast_extract_tcp_metadata(pcap_file)

    # Les analyseurs simples travaillent sur les m√©tadonn√©es
    for metadata in packets_metadata:
        timestamp_analyzer.process_metadata(metadata)
        handshake_analyzer.process_metadata(metadata)
        rtt_analyzer.process_metadata(metadata)
        # etc.

    # Phase 2: Scapy seulement pour analyses complexes (DNS, ICMP, fragments)
    console.print("[cyan]Phase 2: Analyse d√©taill√©e (Scapy)...[/cyan]")
    with PcapReader(pcap_file) as reader:
        for packet in reader:
            if packet.haslayer(DNS):
                dns_analyzer.process_packet(packet)
            if packet.haslayer(ICMP):
                icmp_analyzer.process_packet(packet)
            # etc.
```

**Avantages:**
- ‚úÖ Gains massifs de performance (5-10x)
- ‚úÖ dpkt est tr√®s stable et bien maintenu
- ‚úÖ Garde Scapy pour les cas complexes
- ‚úÖ R√©duction drastique de la consommation m√©moire

**Inconv√©nients:**
- ‚ö†Ô∏è Refactoring important des analyseurs
- ‚ö†Ô∏è Besoin de cr√©er des process_metadata() pour chaque analyseur
- ‚ö†Ô∏è D√©pendance suppl√©mentaire (dpkt)
- ‚ö†Ô∏è Tests √† adapter

---

### Option 3: Multiprocessing (Non recommand√©e)

**Pourquoi pas:**
- ‚ùå Complexit√© tr√®s √©lev√©e
- ‚ùå Les paquets TCP doivent √™tre trait√©s dans l'ordre pour l'analyse de flux
- ‚ùå pcap-parallel charge tout en m√©moire (mauvais pour 116MB)
- ‚ùå Overhead de communication inter-processus
- ‚ùå Difficult√© √† partager l'√©tat entre analyseurs

**Verdict:** Les gains ne justifient pas la complexit√© pour ce use case.

---

## üéØ Recommandation Finale

### Plan d'Impl√©mentation en 2 Phases

#### **Phase 1: Quick Wins avec Scapy (1-2 jours)**
Objectif: 2-3x am√©lioration, faible risque

1. ‚úÖ Ajouter `conf.layers.filter()` au d√©but de l'analyse
2. ‚úÖ Optimiser les 5 analyseurs les plus gros:
   - retransmission.py: limiter flow_segments √† 1000 derniers par flux
   - rtt_analyzer.py: cleanup unacked_segments plus agressif
   - temporal_pattern.py: agr√©ger les time_slots plus t√¥t
   - dns_analyzer.py: limiter l'historique DNS
   - burst_analyzer.py: fen√™tres glissantes au lieu de tout stocker

3. ‚úÖ Ne pas stocker d'objets Packet, extraire imm√©diatement
4. ‚úÖ Garbage collection p√©riodique tous les 50k paquets
5. ‚úÖ Utiliser `__slots__` dans les dataclasses

**Tests:**
- Mesurer le temps avant/apr√®s sur le PCAP de 116MB
- V√©rifier que les r√©sultats sont identiques (tests de r√©gression)
- Profiler avec cProfile pour identifier les derniers bottlenecks

#### **Phase 2: Hybride dpkt (3-5 jours) - SI Phase 1 insuffisante**
Objectif: 5-10x am√©lioration

1. ‚úÖ Cr√©er fast_parser.py avec dpkt
2. ‚úÖ Refactorer les analyseurs pour accepter des m√©tadonn√©es
3. ‚úÖ Mode hybride dans cli.py
4. ‚úÖ Tests complets

---

## üìà M√©triques de Succ√®s - R√âSULTATS R√âELS ‚úÖ

| M√©trique | Avant | Objectif Phase 1 | Phase 1 R√©el | Objectif Phase 2 | **Phase 2 R√©el** |
|----------|-------|------------------|--------------|------------------|------------------|
| Temps d'analyse (26MB, 172k) | 94.97 sec | 47 sec | 93.27 sec ‚ùå | 36-48 sec | **43.19 sec ‚úÖ** |
| Paquets/seconde | 1,814 p/s | 3,500 p/s | 1,848 p/s ‚ùå | 4,500 p/s | **3,989 p/s ‚úÖ** |
| Speedup | 1.0x | 2.0x | 1.02x ‚ùå | 2.5-3.0x | **2.20x ‚úÖ** |
| Gain | - | - | 1.7 sec | - | **50.08 sec** |

### ‚úÖ Phase 2 IMPL√âMENT√âE ET VALID√âE

**R√©sultats finaux (PCAP test: 172,321 paquets, 26 MB):**
```
AVANT (Scapy pur):     94.97 sec | 1,814 p/s
Phase 1 (Scapy opt):   93.27 sec | 1,848 p/s | +1.8% ‚ùå insuffisant
Phase 2 (Hybrid dpkt): 43.19 sec | 3,989 p/s | +120% ‚úÖ SUCC√àS!
```

**Verdict:** Phase 1 plafonne √† ~1.8% car Scapy dissection est incompressible.
**Phase 2 atteint 2.2x speedup** avec seulement 1 analyseur migr√© vers dpkt!

---

## üìö Sources et R√©f√©rences

### Performance Scapy:
- [How to improve scapy performance reading large files - Stack Overflow](https://stackoverflow.com/questions/38601091/how-to-improve-scapy-performance-reading-large-files)
- [How to efficiently read a pcap using Scapy - Medium](https://medium.com/a-bit-off/scapy-ways-of-reading-pcaps-1367a05e98a8)
- [Scapy slow performance - GitHub Issues](https://github.com/secdev/scapy/issues/253)
- [Speeding up Scapy - Woefe's Blog](https://blog.woefe.com/posts/faster_scapy.html)

### dpkt Performance:
- [Python Scapy vs dpkt - Stack Overflow](https://stackoverflow.com/questions/30826123/python-scapy-vs-dpkt)
- [pypacker (3x faster than dpkt) - GitHub](https://github.com/mike01/pypacker)
- [dpkt Tutorial - Jon Oberheide](https://jon.oberheide.org/blog/2008/10/15/dpkt-tutorial-2-parsing-a-pcap-file/)

### Scapy Optimizations:
- [Scapy conf.layers.filter() documentation](https://scapy.readthedocs.io/en/latest/usage.html)
- [Scapy speed up sniff performance - Stack Overflow](https://stackoverflow.com/questions/63447758/scapy-speed-up-sniff-performance)

### Multiprocessing:
- [pcap-parallel - PyPI](https://pypi.org/project/pcap-parallel/)
- [Asura - Massive Pcap Analyzer - GitHub](https://github.com/RuoAndo/Asura)

---

## ‚úÖ IMPL√âMENTATION COMPL√âT√âE

### Phase 1: Optimisations Scapy ‚úÖ
- [x] `conf.layers.filter()` pour parsing s√©lectif
- [x] Garbage collection p√©riodique (50k paquets)
- [x] Optimisation timestamp_analyzer haslayer()
- **R√©sultat:** 1.8% gain seulement ‚ùå

### Phase 2: Mode Hybride dpkt + Scapy ‚úÖ
- [x] Installer dpkt>=1.9.8
- [x] Cr√©er `src/parsers/fast_parser.py` avec PacketMetadata
- [x] Modifier timestamp_analyzer pour supporter PacketMetadata
- [x] Cr√©er `analyze_pcap_hybrid()` dans cli.py
- [x] Ajouter option `--mode hybrid` (d√©faut) et `--mode legacy`
- [x] Benchmark: **2.2x speedup confirm√©!** ‚úÖ
- **R√©sultat:** 120% gain (50 secondes √©conomis√©es) ‚úÖ

### üöÄ Prochaines Optimisations Potentielles

**Actuellement seul timestamp_analyzer utilise dpkt.**

Si on migre les analyseurs critiques vers dpkt:
- tcp_handshake ‚Üí PacketMetadata (flags, seq, ack directs)
- retransmission ‚Üí PacketMetadata (seq, ack, timestamps)
- rtt_analyzer ‚Üí PacketMetadata (seq, ack, timestamps)

**Gain potentiel suppl√©mentaire:** 3-4x speedup total au lieu de 2.2x actuel!

### Commandes de Test

```bash
# Mode hybride (d√©faut, 2.2x plus rapide)
pcap_analyzer analyze capture.pcap --mode hybrid

# Mode legacy (Scapy pur)
pcap_analyzer analyze capture.pcap --mode legacy

# Benchmark comparatif
time pcap_analyzer analyze capture.pcap --no-report --mode hybrid
time pcap_analyzer analyze capture.pcap --no-report --mode legacy
```

---

## ‚öôÔ∏è Commandes de Test

```bash
# Benchmark avant optimisation
time pcap_analyzer analyze large_capture.pcap

# Profiling d√©taill√©
python -m cProfile -o profile.stats src/cli.py analyze large_capture.pcap
python -c "import pstats; p = pstats.Stats('profile.stats'); p.sort_stats('cumulative').print_stats(30)"

# Mesure m√©moire
/usr/bin/time -v pcap_analyzer analyze large_capture.pcap  # Linux
```

