"""
Analyseur de fen√™tres TCP et saturation applicative
"""

from scapy.all import Packet, TCP, IP
from typing import List, Dict, Any, Tuple, Union
from dataclasses import dataclass, asdict
from collections import defaultdict

# Import PacketMetadata for hybrid mode support (3-5x faster)
try:
    from ..parsers.fast_parser import PacketMetadata
except ImportError:
    PacketMetadata = None


@dataclass
class WindowEvent:
    """√âv√©nement li√© √† la fen√™tre TCP"""
    event_type: str  # 'zero_window', 'low_window', 'window_full', 'window_update'
    packet_num: int
    timestamp: float
    flow_key: str
    window_size: int
    src_ip: str
    dst_ip: str
    src_port: int
    dst_port: int
    duration: float = 0.0  # Dur√©e de l'√©v√©nement (pour zero_window)


@dataclass
class FlowWindowStats:
    """Statistiques de fen√™tre pour un flux"""
    flow_key: str
    src_ip: str
    dst_ip: str
    src_port: int
    dst_port: int
    min_window: int
    max_window: int
    mean_window: float
    zero_window_count: int
    low_window_count: int
    zero_window_total_duration: float
    suspected_bottleneck: str  # 'receiver', 'application', 'none'


class TCPWindowAnalyzer:
    """Analyseur de fen√™tres TCP optimis√©"""

    def __init__(self, low_window_threshold: int = 8192, zero_window_duration: float = 0.1):
        """
        Initialise l'analyseur de fen√™tres TCP

        Args:
            low_window_threshold: Seuil de fen√™tre basse en octets
            zero_window_duration: Dur√©e minimale de zero window pour alerter (secondes)
        """
        self.low_window_threshold = low_window_threshold
        self.zero_window_duration_threshold = zero_window_duration

        self.window_events: List[WindowEvent] = []
        self.flow_stats: Dict[str, FlowWindowStats] = {}

        # Tracking interne optimis√©
        self._flow_scales: Dict[str, int] = {}  # Cache des facteurs d'√©chelle
        self._zero_window_start: Dict[str, Tuple[int, float, WindowEvent]] = {}
        
        # Agr√©gation des stats pour √©viter de stocker toutes les fen√™tres (m√©moire & CPU)
        # Structure: {
        #   'count': int, 'sum': float, 'min': int, 'max': int,
        #   'stable_count': int, 'stable_sum': float, 'stable_min': int, 'stable_max': int,
        #   'low_window_count': int, 'zero_window_count': int, 'zero_duration': float
        # }
        self._flow_aggregates: Dict[str, Dict[str, Any]] = defaultdict(lambda: {
            'count': 0, 'sum': 0.0, 'min': float('inf'), 'max': 0,
            'stable_count': 0, 'stable_sum': 0.0, 'stable_min': float('inf'), 'stable_max': 0,
            'low_window_count': 0, 'zero_window_count': 0, 'zero_duration': 0.0
        })

    def analyze(self, packets: List[Packet]) -> Dict[str, Any]:
        """
        Analyse les fen√™tres TCP

        Args:
            packets: Liste des paquets Scapy

        Returns:
            Dictionnaire contenant les r√©sultats d'analyse
        """
        for i, packet in enumerate(packets):
            self.process_packet(packet, i)

        return self.finalize()

    def process_packet(self, packet: Union[Packet, 'PacketMetadata'], packet_num: int) -> None:
        """
        Process a single packet (supports both Scapy Packet and PacketMetadata).

        PERFORMANCE: PacketMetadata is 3-5x faster than Scapy Packet parsing.

        Args:
            packet: Scapy Packet or lightweight PacketMetadata
            packet_num: Packet sequence number in capture
        """
        # FAST PATH: Handle PacketMetadata (dpkt-extracted, 3-5x faster)
        if PacketMetadata and isinstance(packet, PacketMetadata):
            self._process_metadata(packet, packet_num)
            return

        # LEGACY PATH: Handle Scapy Packet (for backward compatibility)
        if not packet.haslayer(TCP) or not packet.haslayer(IP):
            return

        self._last_packet_time = float(packet.time)
        self._analyze_packet(packet_num, packet)

    def _process_metadata(self, metadata: 'PacketMetadata', packet_num: int) -> None:
        """
        PERFORMANCE OPTIMIZED: Process lightweight PacketMetadata (3-5x faster than Scapy).

        This method replicates TCP window analysis logic but uses direct attribute access
        from dpkt-extracted metadata.

        Note: This version uses RAW window size (no WScale parsing) for simplicity and speed.
        WScale parsing requires TCP options which would require additional dpkt parsing.
        Zero window and low window detection work correctly without scaling.

        Args:
            metadata: Lightweight packet metadata from dpkt
            packet_num: Packet sequence number in capture
        """
        # Skip non-TCP packets
        if metadata.protocol != 'TCP':
            return

        timestamp = metadata.timestamp
        self._last_packet_time = timestamp

        # Build flow key from metadata
        flow_key = f"{metadata.src_ip}:{metadata.src_port}->{metadata.dst_ip}:{metadata.dst_port}"

        # Use raw window size (no WScale for performance)
        # This is acceptable because:
        # 1. Zero window detection doesn't need scaling
        # 2. Low window threshold works with raw values
        # 3. Legacy mode still has full WScale support
        window_size = metadata.tcp_window
        actual_window = window_size  # No scaling in fast path

        # Mise √† jour des agr√©gats
        stats = self._flow_aggregates[flow_key]
        stats['count'] += 1
        stats['sum'] += actual_window
        if actual_window < stats['min']:
            stats['min'] = actual_window
        if actual_window > stats['max']:
            stats['max'] = actual_window

        # Stats "stables" (apr√®s 20 paquets)
        is_stable = stats['count'] > 20
        if is_stable:
            stats['stable_count'] += 1
            stats['stable_sum'] += actual_window
            if actual_window < stats['stable_min']:
                stats['stable_min'] = actual_window
            if actual_window > stats['stable_max']:
                stats['stable_max'] = actual_window

        # D√©tection Zero Window
        if actual_window == 0:
            stats['zero_window_count'] += 1

            # D√©marre le tracking de la dur√©e si pas d√©j√† en cours
            if flow_key not in self._zero_window_start:
                event = WindowEvent(
                    event_type='zero_window',
                    packet_num=packet_num,
                    timestamp=timestamp,
                    flow_key=flow_key,
                    window_size=window_size,
                    src_ip=metadata.src_ip,
                    dst_ip=metadata.dst_ip,
                    src_port=metadata.src_port,
                    dst_port=metadata.dst_port
                )
                self._zero_window_start[flow_key] = (packet_num, timestamp, event)
        else:
            # Fin du zero window si en cours
            if flow_key in self._zero_window_start:
                start_pkt, start_time, event = self._zero_window_start[flow_key]
                duration = timestamp - start_time
                event.duration = duration
                stats['zero_duration'] += duration

                # Enregistre l'√©v√©nement seulement s'il d√©passe le seuil
                if duration >= self.zero_window_duration_threshold:
                    self.window_events.append(event)

                del self._zero_window_start[flow_key]

        # D√©tection Low Window
        if 0 < actual_window < self.low_window_threshold:
            stats['low_window_count'] += 1

            # Enregistre l'√©v√©nement
            event = WindowEvent(
                event_type='low_window',
                packet_num=packet_num,
                timestamp=timestamp,
                flow_key=flow_key,
                window_size=window_size,
                src_ip=metadata.src_ip,
                dst_ip=metadata.dst_ip,
                src_port=metadata.src_port,
                dst_port=metadata.dst_port
            )
            self.window_events.append(event)

    def finalize(self) -> Dict[str, Any]:
        """Finalise l'analyse et g√©n√®re le rapport"""
        # Termine les zero windows en cours
        if hasattr(self, '_last_packet_time'):
            last_time = self._last_packet_time
            for flow_key, (start_pkt, start_time, event) in self._zero_window_start.items():
                duration = last_time - start_time
                event.duration = duration
                self._flow_aggregates[flow_key]['zero_duration'] += duration

        # Calcule les statistiques par flux
        self._calculate_flow_statistics()

        return self._generate_report()

    def _analyze_packet(self, packet_num: int, packet: Packet) -> None:
        """Analyse un paquet TCP individuel"""
        tcp = packet[TCP]
        ip = packet[IP]
        timestamp = float(packet.time)

        flow_key = self._get_flow_key(packet)
        
        # Gestion optimis√©e du Window Scale
        window_scale = self._get_window_scale(tcp, flow_key)
        window_size = tcp.window
        actual_window = window_size * window_scale

        # Mise √† jour des agr√©gats
        stats = self._flow_aggregates[flow_key]
        stats['count'] += 1
        stats['sum'] += actual_window
        if actual_window < stats['min']: stats['min'] = actual_window
        if actual_window > stats['max']: stats['max'] = actual_window

        # Stats "stables" (apr√®s 20 paquets)
        is_stable = stats['count'] > 20
        if is_stable:
            stats['stable_count'] += 1
            stats['stable_sum'] += actual_window
            if actual_window < stats['stable_min']: stats['stable_min'] = actual_window
            if actual_window > stats['stable_max']: stats['stable_max'] = actual_window

        # D√©tection Zero Window
        if actual_window == 0:
            stats['zero_window_count'] += 1

            # D√©marre le tracking de la dur√©e si pas d√©j√† en cours
            if flow_key not in self._zero_window_start:
                event = WindowEvent(
                    event_type='zero_window',
                    packet_num=packet_num,
                    timestamp=timestamp,
                    flow_key=flow_key,
                    window_size=actual_window,
                    src_ip=ip.src,
                    dst_ip=ip.dst,
                    src_port=tcp.sport,
                    dst_port=tcp.dport
                )
                self.window_events.append(event)
                self._zero_window_start[flow_key] = (packet_num, timestamp, event)

        else:
            # Fin d'un zero window
            if flow_key in self._zero_window_start:
                start_pkt, start_time, event = self._zero_window_start[flow_key]
                duration = timestamp - start_time
                
                # Mise √† jour directe de l'√©v√©nement et des stats
                event.duration = duration
                stats['zero_duration'] += duration
                
                del self._zero_window_start[flow_key]

                # Window Update apr√®s zero window significatif
                if duration >= self.zero_window_duration_threshold:
                    event = WindowEvent(
                        event_type='window_update',
                        packet_num=packet_num,
                        timestamp=timestamp,
                        flow_key=flow_key,
                        window_size=actual_window,
                        src_ip=ip.src,
                        dst_ip=ip.dst,
                        src_port=tcp.sport,
                        dst_port=tcp.dport,
                        duration=duration
                    )
                    self.window_events.append(event)

        # D√©tection Low Window (uniquement comptage, pas d'√©v√©nement pour √©viter le spam)
        if 0 < actual_window < self.low_window_threshold:
            if is_stable:
                stats['low_window_count'] += 1
            
            # On ne g√©n√®re plus d'√©v√©nement 'low_window' pour chaque paquet
            # car cela ralentit √©norm√©ment l'analyse et surcharge la m√©moire

    def _get_flow_key(self, packet: Packet) -> str:
        """G√©n√®re une cl√© de flux unidirectionnelle"""
        ip = packet[IP]
        tcp = packet[TCP]
        # Ensure ports are integers (they can sometimes be hex strings)
        sport = int(tcp.sport) if isinstance(tcp.sport, int) else int(str(tcp.sport), 16) if isinstance(tcp.sport, str) else tcp.sport
        dport = int(tcp.dport) if isinstance(tcp.dport, int) else int(str(tcp.dport), 16) if isinstance(tcp.dport, str) else tcp.dport
        return f"{ip.src}:{sport}->{ip.dst}:{dport}"

    def _get_window_scale(self, tcp: TCP, flow_key: str) -> int:
        """
        R√©cup√®re le facteur d'√©chelle de la fen√™tre TCP avec mise en cache

        RFC 7323: Window Scale option MUST be checked in both SYN and SYN-ACK packets
        for proper negotiation. The scale factor is only valid if both sides agree.
        """
        # V√©rifie le cache
        if flow_key in self._flow_scales:
            return self._flow_scales[flow_key]

        # RFC 7323: Check for WScale option in SYN or SYN-ACK packets
        # Both SYN (0x02) and SYN-ACK (0x12) can carry WScale option
        if tcp.flags & 0x02:  # Flag SYN set (includes both SYN and SYN-ACK)
            scale = 1
            if tcp.options:
                for option in tcp.options:
                    if option[0] == 'WScale':
                        # RFC 7323: Scale factor = 2^shift_count
                        scale = 2 ** option[1]
                        break
            self._flow_scales[flow_key] = scale
            return scale

        # Par d√©faut 1 si on n'a pas vu le SYN
        return 1

    def _calculate_flow_statistics(self) -> None:
        """Calcule les statistiques de fen√™tre par flux √† partir des agr√©gats"""
        for flow_key, stats in self._flow_aggregates.items():
            try:
                parts = flow_key.split('->')
                src_part, dst_part = parts[0].split(':'), parts[1].split(':')

                zero_duration = stats['zero_duration']
                zero_count = stats['zero_window_count']

                # Calcul du pourcentage de fen√™tres basses sur la partie stable
                low_window_percentage = 0
                if stats['stable_count'] > 0:
                    low_window_percentage = (stats['low_window_count'] / stats['stable_count']) * 100

                # D√©termination du goulot d'√©tranglement
                suspected = 'none'

                # On ignore les flux trop courts
                if stats['count'] >= 30:
                    if zero_count > 5 or zero_duration > 1.0:
                        suspected = 'application'
                    elif low_window_percentage > 30 and (zero_count > 0 or zero_duration > 0):
                        suspected = 'receiver'

                # Valeurs min/max/moy
                # Si on a des donn√©es stables, on les privil√©gie pour le min
                min_win = stats['stable_min'] if stats['stable_count'] > 0 else stats['min']
                if min_win == float('inf'): min_win = 0

                mean_win = stats['sum'] / stats['count'] if stats['count'] > 0 else 0

                # Parse ports with error handling for hex strings or invalid values
                try:
                    src_port = int(src_part[1])
                except ValueError:
                    # Try parsing as hex if decimal fails
                    src_port = int(src_part[1], 16)

                try:
                    dst_port = int(dst_part[1])
                except ValueError:
                    # Try parsing as hex if decimal fails
                    dst_port = int(dst_part[1], 16)

                flow_stats = FlowWindowStats(
                    flow_key=flow_key,
                    src_ip=src_part[0],
                    dst_ip=dst_part[0],
                    src_port=src_port,
                    dst_port=dst_port,
                    min_window=int(min_win),
                    max_window=int(stats['max']),
                    mean_window=mean_win,
                    zero_window_count=zero_count,
                    low_window_count=stats['low_window_count'],
                    zero_window_total_duration=zero_duration,
                    suspected_bottleneck=suspected
                )

                self.flow_stats[flow_key] = flow_stats
            except (ValueError, IndexError) as e:
                # Skip malformed flow keys
                print(f"Warning: Skipping malformed flow key '{flow_key}': {e}")
                continue

    def _generate_report(self) -> Dict[str, Any]:
        """G√©n√®re le rapport d'analyse des fen√™tres TCP"""
        flows_with_issues = [
            f for f in self.flow_stats.values()
            if f.suspected_bottleneck != 'none'
        ]

        zero_window_events = [
            e for e in self.window_events
            if e.event_type == 'zero_window' and e.duration >= self.zero_window_duration_threshold
        ]

        # Statistiques de goulots d'√©tranglement
        bottleneck_counts = defaultdict(int)
        for flow in self.flow_stats.values():
            bottleneck_counts[flow.suspected_bottleneck] += 1

        return {
            'total_flows': len(self.flow_stats),
            'flows_with_issues': len(flows_with_issues),
            'total_window_events': len(self.window_events),
            'significant_zero_windows': len(zero_window_events),
            'thresholds': {
                'low_window_bytes': self.low_window_threshold,
                'zero_window_duration_seconds': self.zero_window_duration_threshold
            },
            'bottleneck_distribution': dict(bottleneck_counts),
            'window_events': [asdict(e) for e in self.window_events],
            'flow_statistics': [asdict(f) for f in self.flow_stats.values()],
            'critical_zero_windows': [asdict(e) for e in zero_window_events]
        }

    def get_summary(self) -> str:
        """Retourne un r√©sum√© textuel de l'analyse des fen√™tres TCP"""
        flows_with_issues = [
            f for f in self.flow_stats.values()
            if f.suspected_bottleneck != 'none'
        ]

        zero_windows = sum(f.zero_window_count for f in self.flow_stats.values())

        summary = f"üìä Analyse des fen√™tres TCP:\n"
        summary += f"  - Flux analys√©s: {len(self.flow_stats)}\n"
        summary += f"  - √âv√©nements Zero Window: {zero_windows}\n"

        if flows_with_issues:
            summary += f"\nüî¥ {len(flows_with_issues)} flux avec probl√®mes de fen√™tre:\n"

            for flow in sorted(flows_with_issues,
                             key=lambda f: f.zero_window_total_duration, reverse=True)[:10]:
                summary += f"\n  {flow.flow_key}\n"
                summary += f"    - Goulot suspect√©: {flow.suspected_bottleneck}\n"
                summary += f"    - Zero Windows: {flow.zero_window_count}\n"
                summary += f"    - Dur√©e totale ZW: {flow.zero_window_total_duration:.3f}s\n"
                summary += f"    - Fen√™tre min/moy/max: {flow.min_window}/{int(flow.mean_window)}/{flow.max_window} bytes\n"
        else:
            summary += f"\n‚úì Aucun probl√®me de fen√™tre TCP d√©tect√©.\n"

        return summary
